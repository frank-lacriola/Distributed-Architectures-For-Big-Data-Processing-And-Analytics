{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enabling-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "carsPath = \"/user/s292129/data/exam_06_2020/Cars.txt\"\n",
    "carsFailuresPath = \"/user/s292129/data/exam_06_2020/CarsFailures.txt\"\n",
    "out1 = \"exam_0620_out1/\"\n",
    "out2 = \"exam_0620_out2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "practical-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "carsRDD = sc.textFile(carsPath)\n",
    "# schema: carID, Model, Company, City\n",
    "failuresRDD = sc.textFile(carsFailuresPath).cache()\n",
    "# schema: date, time, carID, FailureType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dying-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterYearsAndType(line):\n",
    "    fields = line.split(',')\n",
    "    carID = fields[2]\n",
    "    date = fields[0]\n",
    "    failureType = fields[3]\n",
    "    if ((date.startswith(\"2017\") or date.startswith(\"2018\")) and \\\n",
    "        failureType == \"Engine\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "filteredFailuresRDD = failuresRDD.filter(filterYearsAndType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hindu-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapIdFailuresPerYear(line):\n",
    "    fields = line.split(\",\")\n",
    "    date = fields[0]\n",
    "    carID = fields[2]\n",
    "    if (date.startswith('2017')):\n",
    "        return (carID, (1, 0))\n",
    "    elif (date.startswith('2018')):\n",
    "        return (carID, (0, 1))\n",
    "    \n",
    "mappedRDD = filteredFailuresRDD.map(mapIdFailuresPerYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "existing-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "carID_numFailPerYear = mappedRDD.reduceByKey(lambda v1, v2: (v1[0]+v2[0], v1[1]+v2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "marked-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredIncreasing = carID_numFailPerYear.filter(lambda pair: pair[1][1] > pair[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "asian-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Car15', (0, 9))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredIncreasing.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "preliminary-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "carID_modelRDD = carsRDD.map(lambda line: (line.split(',')[0], line.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funky-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "carID_modelRDD.join(filteredIncreasing).map(lambda pair: (pair[0], pair[1][0]))\\\n",
    ".saveAsTextFile(out1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-argentina",
   "metadata": {},
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "supreme-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "carDates = failuresRDD.map(lambda line: (line.split(',')[2], line.split(',')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "respective-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is already provided \n",
    "from datetime import datetime, timedelta\n",
    "def previousDate(mydate):\n",
    "    currentDate=datetime.strptime(mydate,\"%Y/%m/%d\")\n",
    "    prevDate=currentDate-timedelta(days=1)\n",
    "    return prevDate.strftime(\"%Y/%m/%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "characteristic-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "carDatesDistinct = carDates.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "blond-breach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Car15', '2018/01/05'),\n",
       " ('Car15', '2018/01/06'),\n",
       " ('Car15', '2018/01/07'),\n",
       " ('Car15', '2018/01/08'),\n",
       " ('Car15', '2018/01/12'),\n",
       " ('Car12', '2017/01/06'),\n",
       " ('Car12', '2017/01/08'),\n",
       " ('Car15', '2018/01/09'),\n",
       " ('Car15', '2018/01/10'),\n",
       " ('Car15', '2018/01/11'),\n",
       " ('Car12', '2018/01/05'),\n",
       " ('Car12', '2018/01/06'),\n",
       " ('Car12', '2018/01/07'),\n",
       " ('Car12', '2018/01/08'),\n",
       " ('Car12', '2017/01/05'),\n",
       " ('Car12', '2017/01/07'),\n",
       " ('Car12', '2017/01/09')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carDatesDistinct.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "frequent-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emitTwoPairsPerFailure(pair):\n",
    "    carID = pair[0]\n",
    "    date = pair[1]\n",
    "    listOfPairs = [((carID, date), 1), ((carID, previousDate(date)), 1)]\n",
    "    return listOfPairs\n",
    "\n",
    "mappedRDD = carDatesDistinct.flatMap(emitTwoPairsPerFailure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "brilliant-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "carIDdate_numOfFailures = mappedRDD.reduceByKey(lambda v1, v2: v1+v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "blessed-electricity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Car15', '2018/01/05'), 2),\n",
       " (('Car15', '2018/01/06'), 2),\n",
       " (('Car15', '2018/01/07'), 2),\n",
       " (('Car15', '2018/01/08'), 2),\n",
       " (('Car15', '2018/01/12'), 1),\n",
       " (('Car12', '2017/01/06'), 2),\n",
       " (('Car12', '2017/01/08'), 2),\n",
       " (('Car12', '2018/01/04'), 1),\n",
       " (('Car15', '2018/01/04'), 1),\n",
       " (('Car15', '2018/01/11'), 2),\n",
       " (('Car12', '2017/01/05'), 2),\n",
       " (('Car12', '2017/01/07'), 2),\n",
       " (('Car15', '2018/01/09'), 2),\n",
       " (('Car15', '2018/01/10'), 2),\n",
       " (('Car12', '2018/01/05'), 2),\n",
       " (('Car12', '2018/01/06'), 2),\n",
       " (('Car12', '2018/01/07'), 2),\n",
       " (('Car12', '2018/01/08'), 1),\n",
       " (('Car12', '2017/01/04'), 1),\n",
       " (('Car12', '2017/01/09'), 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carIDdate_numOfFailures.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "protective-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "carIDdate_numOfFailures.filter(lambda pair: pair[1] == 2)\\\n",
    ".keys().saveAsTextFile(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-handle",
   "metadata": {},
   "source": [
    "# SQL BASED SOLUTION - ERRATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "described-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "failuresDF = spark.read.load(carsFailuresPath,\\\n",
    "               format=\"csv\",\n",
    "               header=False,\n",
    "               inferSchema=True).withColumnRenamed('_c0','date')\\\n",
    ".withColumnRenamed('_c1','time').withColumnRenamed('_c2','carID')\\\n",
    ".withColumnRenamed('_c2','failureType').createOrReplaceTempView('failures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "accessible-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail2017DF = spark.sql('SELECT carID, count(*) AS count17\\\n",
    "            FROM failures \\\n",
    "            WHERE date >= \"2017/01/01\" AND date <= \"2017/12/31\" \\\n",
    "            GROUP BY carID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "velvet-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail2018DF = spark.sql('SELECT carID, count(*) AS count18\\\n",
    "            FROM failures \\\n",
    "            WHERE date >= \"2018/01/01\" AND date <= \"2018/12/31\" \\\n",
    "            GROUP BY carID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "maritime-figure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|carID|count17|\n",
      "+-----+-------+\n",
      "|Car12|      6|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fail2017DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "subjective-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "increasingFailCarsDF = fail2017DF.join(fail2018DF,fail2017DF.carID==fail2018DF.carID)\\\n",
    ".filter(\"count17 < count18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "needed-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+\n",
      "|carID|count17|carID|count18|\n",
      "+-----+-------+-----+-------+\n",
      "+-----+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "increasingFailCarsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "inclusive-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "carsDF = spark.read.load(carsPath, format='csv', header=False, inferSchema=True)\\\n",
    ".withColumnRenamed('_c0','carID').withColumnRenamed('_c1','model')\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "demographic-photographer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+-----+\n",
      "|carID| model|  _c2|  _c3|\n",
      "+-----+------+-----+-----+\n",
      "|Car12| Panda|  FCA|Paris|\n",
      "|Car15|Model1|Honda|Paris|\n",
      "|Car16|Model2|  FCA|Paris|\n",
      "|Car17|Model3|Honda| Rome|\n",
      "+-----+------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "carsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "encouraging-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "carsDF.createOrReplaceTempView('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT carID, model \\\n",
    "           FROM increasingCars JOIN cars ON increasingCars.carID = cars.carID \\\n",
    "           ').write.csv(out1,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-suggestion",
   "metadata": {},
   "source": [
    "# Task B - ERRATO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT DISTINCT carID, date \\\n",
    "            FROM failures').createOrReplaceTempView('distinctfailures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevDateDF = spark.sql('SELECT carID, previousDate(date) AS prevDate \\\n",
    "                        FROM distinctfailures ').createOrReD('prevDateFailures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT carID, date \\\n",
    "           FROM failures JOIN prevDateFailures ON failures.carID=prevDateFailures.carID \\\n",
    "           AND failures.date=prevDateFailures.prevDate \\\n",
    "           GROUP BY carID, date \\\n",
    "           HAVING count(*)=2').write.csv(out2,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
