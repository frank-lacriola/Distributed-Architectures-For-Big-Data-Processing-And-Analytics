{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "purple-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_path = \"/data/students/bigdata-01QYD/Lab6_DBD/register.csv\"\n",
    "stations_path = \"/data/students/bigdata-01QYD/Lab6_DBD/stations.csv\"\n",
    "outputPath = \"res_out_Lab6/\"\n",
    "treshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "level-swimming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register.csv format: stationID\\tTimeStamp\\tUsedSlots\\tFreeSlots\n",
    "registerRDD = sc.textFile(register_path)\n",
    "# we need to filter the header and the wrong data\n",
    "def filterHeadANDwrongData(line):\n",
    "    if line.startswith(\"stat\"):\n",
    "        return False\n",
    "    lineSplit = line.split(\"\\t\")\n",
    "    if int(lineSplit[2]) != 0 or int(lineSplit[3]) != 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "filteredRegisterRDD = registerRDD.filter(filterHeadANDwrongData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "familiar-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------Task 1 ----------------\n",
    "# We have to identify the most critical timeslot for each station\n",
    "# \"day of the week-hour\" is a timeslot and is associated with all the readings associated with that pair\n",
    "# criticality of a station S_i in the timeslot T_j = \n",
    "# (num of readings with num of free slots = 0 for (S_i, T_j) ) / (total num of readings in the pair (S_i, T_j)\n",
    "from datetime import datetime\n",
    "\n",
    "# Creating pairs (S_i, T_j)\n",
    "def createPairs(line):\n",
    "    lineSplit = line.split(\"\\t\")\n",
    "    S_j = lineSplit[0]\n",
    "    timestamp = lineSplit[1]\n",
    "    datetimeObj = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
    "    T_j = (datetimeObj.strftime(\"%a\"), datetimeObj.hour)\n",
    "    return ((S_j, T_j), int(lineSplit[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "swedish-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsRDD = filteredRegisterRDD.map(createPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "institutional-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsValueGroupedRDD = pairsRDD.groupByKey().cache()\n",
    "#pairsValueGroupedRDD = pairsValueGroupedRDD.mapValues(lambda value: list(value)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "powerful-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the criticality value for each pair\n",
    "def computeCriticalityValue(line):\n",
    "    zeroCounter = 0\n",
    "    for value in line[1]:\n",
    "        if value == 0:\n",
    "            zeroCounter += 1\n",
    "    critValue = zeroCounter/len(line[1])\n",
    "    return (line[0], critValue)\n",
    "    \n",
    "pairsCritValueRDD = pairsValueGroupedRDD.map(computeCriticalityValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "boxed-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We select only pairs with crit value > treshold\n",
    "pairsCritValueFilteredRDD = pairsCritValueRDD.filter(lambda pair: pair[1] >= treshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hazardous-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsReMapS_idTupleRDD = pairsCritValueFilteredRDD.map(lambda pair:\\\n",
    "                                                       (pair[0][0], (pair[0][1], pair[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecological-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupByKey to obtain a list of tuples with ((weekday, hour), criticalValue) for each station\n",
    "pairsReMappedGroupedRDD = pairsReMapS_idTupleRDD.groupByKey().cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "substantial-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairsReMappedGroupedRDD = pairsReMappedGroupedRDD.mapValues(lambda v: list(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "surprising-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to select the most critical timeslot for each station (EASIER WITH REDUCEBYKEY)\n",
    "def returnMostCritical(pair):\n",
    "    s_id = pair[0]\n",
    "    Tslot_CritValue_ListOfTuples = pair[1]\n",
    "    maxValue = 0.1\n",
    "    \n",
    "    for i_tuple in Tslot_CritValue_ListOfTuples:\n",
    "        if i_tuple[1] > maxValue:\n",
    "            maxValue = i_tuple[1]\n",
    "            \n",
    "    timeSlotsWithMax = []\n",
    "    for j_tuple in Tslot_CritValue_ListOfTuples:\n",
    "        if j_tuple[1] == maxValue:\n",
    "            timeSlotsWithMax.append(j_tuple)\n",
    "            \n",
    "    if len(timeSlotsWithMax) == 1:\n",
    "        return (s_id, timeSlotsWithMax[0])\n",
    "    else:\n",
    "        minHour = 25\n",
    "        for ts in timeSlotsWithMax:\n",
    "            if ts[0][1] < minHour:\n",
    "                minHour = ts[0][1]\n",
    "        \n",
    "        tsWithMinHour = []\n",
    "        for ts in timeSlotsWithMax:\n",
    "            if ts[0][1] == minHour:\n",
    "                tsWithMinHour.append(ts)\n",
    "        \n",
    "        if len(tsWithMinHour) == 1:\n",
    "            return (s_id, tsWithMinHour[0])\n",
    "        else: \n",
    "            minDay = tsWithMinHour[0][0]\n",
    "            pos = 1\n",
    "            while pos < len(tsWithMinHour):\n",
    "                if tsWithMinHour[pos][0] < minDay:\n",
    "                    minDay = tsWithMinHour[pos][0]\n",
    "            \n",
    "            tsMinDay = []\n",
    "            for item in tsWithMinHour:\n",
    "                if item[0][0] == minDay:\n",
    "                    tsMinDay.append(item)\n",
    "            \n",
    "            return (s_id, tsMinDay[0])\n",
    "\n",
    "                \n",
    "#-----------------------------------------------------------------------------\n",
    "#Easier with ReduceByKey\n",
    "pairSidMostCriticalRDD = pairsReMappedGroupedRDD.map(returnMostCritical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "loose-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to store using a KML file: the output file must contain one marker of type\n",
    "# Placemark for each pair characterized by:\n",
    "# StationID, WeekDay and Hour, CriticalityValue, Longitude and Latitude\n",
    "\n",
    "stationsRDD = sc.textFile(stations_path)\n",
    "\n",
    "mappedStationRDD = stationsRDD.map(lambda line: (line.split(\"\\t\")[0],\\\n",
    "                                                 (line.split(\"\\t\")[1], line.split(\"\\t\")[2])))\n",
    "joinedRDD = pairSidMostCriticalRDD.join(mappedStationRDD)\n",
    "#joinedRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-rotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formattazione per KML file\n",
    "def kmlFormatMapping(pair):\n",
    "    name = pair[0]\n",
    "    day = pair[1][0][0][0]\n",
    "    hour = str(pair[1][0][0][1])\n",
    "    critValue = str(pair[1][0][1])\n",
    "    longitude = pair[1][1][0]\n",
    "    latitude = pair[1][1][1]\n",
    "    return \"<Placemark><name>\"+name+\"</name><ExtendedData><Data name=\"\"DayWeek\"\"><value>\"+day+\"</value></Data><Data name=\"\"Hour\"\"><value>\"+hour+\"3</value></Data><Data name=\"\"Criticality\"\"><value>\"\\\n",
    "    +critValue+\"</value></Data></ExtendedData><Point><coordinates>\"+longitude+\",\"+latitude+\"</coordinates></Point></Placemark>\"\n",
    "\n",
    "outputRDD = joinedRDD.map(kmlFormatMapping)\n",
    "outputRDD = outputRDD.coalesce(1)\n",
    "outputRDD.saveAsTextFile(outputPath)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "intense-guyana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-church",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
