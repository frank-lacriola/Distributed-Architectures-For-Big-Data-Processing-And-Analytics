{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "official-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_path = \"/data/students/bigdata-01QYD/Lab6_DBD/register.csv\"\n",
    "stations_path = \"/data/students/bigdata-01QYD/Lab6_DBD/stations.csv\"\n",
    "outputPath = \"res_out_Lab7/\"\n",
    "treshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "crazy-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "registerDF = spark.read.load(register_path,\\\n",
    "                            format=\"csv\",\\\n",
    "                            sep=\"\\t\",\\\n",
    "                            header=True,\\\n",
    "                            inferSchema=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "changing-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "registerFiltered = registerDF.filter(\"used_slots <> 0 OR free_slots <> 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "english-chrome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- used_slots: integer (nullable = true)\n",
      " |-- free_slots: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "registerFiltered.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "overall-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#registerWithTimeSlot = registerFiltered.selectExpr(\"station\",\"date_format(timestamp,'EE') as weekday\",\\\n",
    "#\"hour(timestamp) as hour\",\"used_slots\",\"free_slots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acting-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupedCriticalRegister = registerWithTimeSlot.filter(\"free_slots = 0\").groupBy(\"station\",\"weekday\",\"hour\")\\\n",
    "#.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "recent-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupedTotalReadings = registerWithTimeSlot.groupBy(\"station\",\"weekday\",\"hour\")\\\n",
    "#.count().withColumnRenamed(\"station\",\"station1\").withColumnRenamed(\"weekday\",\"weekday1\").withColumnRenamed(\"hour\",\"hour1\").withColumnRenamed(\"count\",\"countTOT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prompt-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joinedDF = groupedCriticalRegister.join(groupedTotalReadings,\\\n",
    "#                             (groupedCriticalRegister.station == groupedTotalReadings.station1) &\\\n",
    "#                             (groupedCriticalRegister.weekday == groupedTotalReadings.weekday1) &\\\n",
    "#                             (groupedCriticalRegister.hour == groupedTotalReadings.hour1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joinedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "announced-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.udf.register(\"crit_value\", lambda countCrit, countTOT: countCrit/countTOT, \"FLOAT\")\n",
    "\n",
    "#stationTS_withCV = joinedDF.selectExpr(\"station\",\"weekday\",\"hour\",\\\n",
    "#                                       \"crit_value(count, countTOT) AS crit_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "agricultural-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------- ALTERNATIVE SOLUTION ---> AVG\n",
    "#User Defined Function called full(Integer free_slots)\n",
    "# that returns \n",
    "# -- 1 if free_slots is equal to 0\n",
    "# -- 0 if free_slots is greater than 0\n",
    "def fullFunction(free_slots):\n",
    "    if free_slots==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "spark.udf.register(\"full\", fullFunction)\n",
    "\n",
    "stationWeekdayHourDF = registerFiltered.selectExpr(\"station\", \"date_format(timestamp,'EE') as dayofweek\",\\\n",
    "                                             \"hour(timestamp) as hour\", \"full(free_slots) as fullstatus\")\n",
    "rgdStationWeekdayHourDF = stationWeekdayHourDF.groupBy(\"station\", \"dayofweek\", \"hour\")\n",
    "# The criticality is equal to the average of fullStatus\n",
    "stationWeekdayHourCriticalityDF = rgdStationWeekdayHourDF.agg({\"fullStatus\": \"avg\"})\\\n",
    ".withColumnRenamed(\"avg(fullStatus)\", \"criticality\")\n",
    "\n",
    "#------------------------END OF ALTERNATIVE SOL. --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cooperative-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- crit_value: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stationTS_withCV.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "female-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "tresholdFilteringDF = stationWeekdayHourCriticalityDF.filter(\"criticality > \"+str(treshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "major-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsDF = spark.read.load(stations_path,\\\n",
    "                             format=\"csv\",\\\n",
    "                             sep=\"\\t\",\\\n",
    "                             header=True,\\\n",
    "                             inferSchema=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "robust-failing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stationsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "southern-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedDF = tresholdFilteringDF.join(stationsDF,\\\n",
    "                     stationTS_withCV.station==stationsDF.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "hispanic-earth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station: integer (nullable = true)\n",
      " |-- dayofweek: string (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- criticality: double (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "informal-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToStore = joinedDF.select(\"station\",\"dayofweek\",\"hour\",\"criticality\",\\\n",
    "                            \"longitude\",\"latitude\")\\\n",
    ".sort(joinedDF.criticality.desc(), joinedDF.station, joinedDF.dayofweek, joinedDF.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "outdoor-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToStore.coalesce(1).write.csv(outputPath, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-replacement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
